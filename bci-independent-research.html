<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Ava Lakmazaheri</title>
    <link rel="icon" href="img/fav.png" type="image/x-icon">

    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="ionicons/css/ionicons.min.css" rel="stylesheet">

    <!-- main css -->
    <link href="css/style.css" rel="stylesheet">


    <!-- modernizr -->
    <script src="js/modernizr.js"></script>

    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
</head>

<body>

    <!-- Preloader -->
    <div id="preloader">
        <div class="pre-container">
            <div class="spinner">
                <div class="double-bounce1"></div>
                <div class="double-bounce2"></div>
            </div>
        </div>
    </div>
    <!-- end Preloader -->

    <div class="container-fluid">
       <!-- box-header -->
        <header class="box-header">
            <div class="box-logo">
                <a href="index.html"><img src="img/logo.png" height="80" width="250" alt="Logo"></a>
            </div>
            <!-- box-nav -->
            <a class="box-primary-nav-trigger" href="#0">
                <span class="box-menu-text">Menu</span><span class="box-menu-icon"></span>
            </a>
            <!-- box-primary-nav-trigger -->
        </header>
        <!-- end box-header -->

        <!-- nav -->
        <nav>
            <ul class="box-primary-nav">
                <li class="box-label">About me</li>

                <li><a href="index.html">Overview</a></li>
                <li><a href="about.html">About me</a></li>
                <li><a href="portfolio.html">portfolio</a> <i class="ion-ios-circle-filled color"></i></li>
                <li><a href="contact.html">contact me</a></li>
            </ul>
        </nav>
        <!-- end nav -->
    </div>

    <!-- top-bar -->
    <div class="top-bar">
        <h1>Brain-Actuated Robotics</h1>
        <p><a href="index.html">Home</a> / <a href="portfolio.html">portfolio</a> / BCI Independent Research</p>
    </div>
    <!-- end top-bar -->

    <!-- main-container -->
    <div class="container main-container">
        <div class="col-md-12">
            <img src="img/Year2/Martie.png" alt="" class="img-responsive" />
            <div class="h-30"></div>
        </div>

        <div class="col-md-12">
            <h3 class="text-uppercase">Brain-Actuated Robotics</h3>
            <i><h4>Independent Research</h4></i>
            <h5>A Logic-Based Approach for Multimodal Programming and Operation of Assistive Humanoid Robots</h5>
            <div class="h-30"></div>
        </div>

        <div class="col-md-9">
            <i>Project Summary:</i>
            <p>This work addresses how non-invasive technologies can be used as a practical and effective solution to convert brainwaves into movement of robotic prosthetics for manipulating objects. It explores how the brain-computer interfacing process can be tailored to the individual, providing multimodal control to reduce mental taxation and the use of natural language for an intuitive means of externalizing intent.</p>
        </div>

        <div class="col-md-3">
            <ul class="cat-ul">
                <li><i class="ion-ios-circle-filled"></i> Systems Engineering</li>
                <li><i class="ion-ios-circle-filled"></i> Natural Language Programming </li>
                <li><i class="ion-ios-circle-filled"></i> Robotics </li>
            </ul>
        </div>

        <div class="col-md-12">
            <center>
                <img src="img/HS/systemoverview.png" alt="image" align="top" width = 50%  style= "PADDING-TOP: 20px ; PADDING-RIGHT: 10%;"/>
                <video width=30% controls align="top">
                <source src="img/HS/regionalFair.mp4" type="video/mp4">
                </video>
                <br>
                <i><span class="padding">System Overview</span></i>
                <i><span> Demonstration Video</span></i>
                <div class="paddedline"> </div>
            </center>

            <i>Project Details:</i>
            <p>In this study, the user wore a Neurosky Mindwave, a commercially available electroencephalography (EEG) headset that records brain activity from the scalp. Three techniques (blinking, jaw clenching, and focused attention) were selected to induce brain signals. Data was received and processed with OpenVibe, an on off-the-shelf BCI software environment.</p>
            <p>The user can formulate natural language sentences word-by-word via biosignals using a graphical user interface. If a signal generation event occurs when the marker points to a keyword, it is selected for processing. Modes of signal generation include focused attention, eye blinking, and jaw clenching. Further, if desired, the user can activate a voice control mode at any time.</p>
            <p>The user can also program the system via biosignals by defining and storing up to 25 sets of sentences (“paragraphs”) as programs to be retrieved and executed at a later time.</p>

            <center>
            <div class="paddedline"> </div>
            <img src="img/HS/gui.png" alt="" width = 40% />
            <div class="paddedline"> </div>
            <i>Graphical User Interface</i>
            <div class="paddedline"> </div>
            </center>

            <p>Natural language sentences are mapped into logical predicates using set operations and template matching.</p>
            <center>
                <div class="paddedline"> </div>
                <img src="img/HS/nlp.PNG" alt="" width = 95% />
                <div class="paddedline"> </div>
                <i>Sample Set Contents and Template Matching Process</i>
                <div class="paddedline"> </div>
            </center>

            <p>Domain knowledge is represented using logical expressions, including the behavior of and relationships among robot parts. The underlying computations for making the robot respond to user requests are modeled using theorem proving. </p>
            <center>
                <div class="paddedline"> </div>
                <img src="img/HS/nlp3.png" alt="" width = 75%/>
                <div class="paddedline"> </div>
                <i>Theorem Proving. In this example, the “arm up” command is distilled to individual servo instructions.</i>
                <div class="paddedline"> </div>
            </center>

            <p>A life-size humanoid robot was designed and built for performing object manipulation and navigation tasks. In addition, an experimental model robotic wheelchair was designed and constructed with mountable robotic arms and a transformable seat capable of moving to an upright position.</p>

            <center>
                <div class="paddedline"> </div>
                <img src="img/HS/Martie.png" alt="" width = 30% style= "PADDING-TOP: 20px ; PADDING-RIGHT: 30px;"/>
                <img src="img/HS/chair1.PNG" alt="" width = 30% style= "PADDING-TOP: 20px ; PADDING-RIGHT: 30px;"/>
                <img src="img/HS/chair2.PNG" alt="" width = 30% style= "PADDING-TOP: 20px ; PADDING-RIGHT: 30px;"/>

                <div class="paddedline"> </div>
                <i>BCI End Devices</i>
                <div class="paddedline"> </div>
            </center>

            <p>Both robots have two cameras for object recognition and motion planning. An operational space is defined and tagged with keywords for natural language-based object manipulation. </p>

            <center>
                <div class="paddedline"> </div>
                <img src="img/HS/opspace.png" alt="" width = 30% />
                <div class="paddedline"> </div>
                <i>Tagged 3D Operational Space</i>
                <div class="paddedline"> </div>
            </center>

            <i>Results & Implications</i>
            <p>Each signal generation technique reported over 90% accuracy to generate natural language sentences. The wheelchair was fully operational using the BCI system; the humanoid effectively employed object manipulation and rudimentary navigation. The video below shows the system in action.</p>
            <p>The efficacy of this system was highly competitive for BCI research with the added safety and cost benefits of non-invasive technologies. Many software and hardware components were open-source or inexpensive, making this solution more commercially-viable.</p>
            <p>Various design choices proved beneficial in reducing mental taxation, including multimodality which combats fatigue and the use of natural language which provides an intuitive means for externalizing intent. Further, support for machine intelligence through the logical inference engine and the programming capability eases user operation for frequent, complex processes.</p>
            <p>These results confirm the viability of less invasive, more cost-effective solutions. Continuation of this work will help expand the development of more flexible assistive tools that can enhance mobility and further independence for those with physical disabilities. </p>

            <i>Read More:</i>
            <p>The following report covers the methodology (including signal processing algorithms, natural language processing schema, and robot control algorithms) and performance results in more detail.*</p>

            <a href="img/HS/research-report.pdf" download> Download Report</a>
            <p></p>
            <p>* This report reflects a previous iteration of the mechanical system, in which the humanoid was significantly less dexterous and the hybrid wheelchair had yet to be developed.</p>
        </div>
    </div>
    <!-- end main-container -->

    <!-- footer -->
    <footer>
        <div class="container-fluid">
            <p class="copyright">ava.lakmazaheri@students.olin.edu</p>
        </div>
    </footer>
    <!-- end footer -->

    <!-- back to top -->
    <a href="#0" class="cd-top"><i class="ion-android-arrow-up"></i></a>
    <!-- end back to top -->




    <!-- jQuery -->
    <script src="js/jquery-2.1.1.js"></script>
    <!--  plugins -->
    <script src="js/bootstrap.min.js"></script>
    <script src="js/menu.js"></script>
    <script src="js/animated-headline.js"></script>
    <script src="js/isotope.pkgd.min.js"></script>


    <!--  custom script -->
    <script src="js/custom.js"></script>

</body>

</html>
